{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lbp_features(image):\n",
    "    num_points = 24\n",
    "    radius = 3\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # Extrahiere die LBP-Merkmale aus dem Graustufenbild\n",
    "    lbp = local_binary_pattern(gray_image, num_points, radius, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, num_points + 3), range=(0, num_points + 2))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-7)\n",
    "    return hist\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Create a HOG detector with customized parameters\n",
    "    winSize = (64, 64)\n",
    "    blockSize = (32, 32)  \n",
    "    blockStride = (16, 16)\n",
    "    cellSize = (16, 16)\n",
    "    nbins = 9\n",
    "    hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\n",
    "    # Extract the HOG features\n",
    "    hog_features = hog.compute(gray_image)\n",
    "    return hog_features\n",
    "\n",
    "def predict_image_HOG(image, classifier, hog_pca_transformer):\n",
    "    predict_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Verkleinere das Bild\n",
    "    predict_resized_image = cv2.resize(predict_image, (255, 255))\n",
    "    # Extrahiere die HOG-Merkmale\n",
    "    hog_features = extract_hog_features(predict_resized_image)\n",
    "    hog_features_pca = hog_pca_transformer.transform(hog_features.reshape(1, -1))\n",
    "  # Führe die Vorhersage mit dem Klassifikator durch\n",
    "    probabilities = classifier.predict_proba(hog_features_pca)[0]\n",
    "    predicted_class_index = np.argmax(probabilities)\n",
    "    predicted_class_name = classifier.classes_[predicted_class_index]\n",
    "    confidence = probabilities[predicted_class_index]\n",
    "    return predicted_class_name, confidence\n",
    "\n",
    "def predict_image_LBP(image, classifier):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Verkleinere das Bild\n",
    "    resized_image = cv2.resize(image, (255, 255))\n",
    "    # Extrahiere die LBP-Merkmale\n",
    "    lbp_features = extract_lbp_features(resized_image)\n",
    "    # Führe die Vorhersage mit dem Klassifikator durch\n",
    "    prediction = classifier.predict([lbp_features])[0]\n",
    "    # Bestimme die Vertrauenswahrscheinlichkeit für die Vorhersage\n",
    "    confidence = max(classifier.predict_proba([lbp_features])[0])\n",
    "    return prediction, confidence\n",
    "    \n",
    "def detect_face(image_path):\n",
    "    # Laden des Gesichtserkennungs-Klassifikators (Haar-Cascade)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    # Laden des Bildes\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is not None:\n",
    "        # Konvertieren des Bildes in Graustufen\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # Gesichter im Bild erkennen\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(200, 200))\n",
    "        if len(faces) > 0:\n",
    "            # Nehme das erste erkannte Gesicht\n",
    "            (x, y, w, h) = faces[0]\n",
    "            # Schneide das Gesicht aus\n",
    "            face = image[y:y+h, x:x+w]\n",
    "             # Zeichne ein Rechteck um das erkannte Gesicht\n",
    "            ##cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            return face\n",
    "        else:\n",
    "            print(f\"No face detected in {image_path}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "        return None\n",
    "\n",
    "# Laden der Bilder und Extrahieren der Merkmale\n",
    "def load_images_and_extract_features(data_folder, feature_extractor):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for folder_name in os.listdir(data_folder):\n",
    "        folder_path = os.path.join(data_folder, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                image_path = os.path.join(folder_path, file_name)\n",
    "                face = detect_face(image_path)\n",
    "                if face is not None:\n",
    "                    # Convert the image from BGR to RGB\n",
    "                    rgb_face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "                    resized_face = cv2.resize(rgb_face, (255, 255))\n",
    "                    feature = feature_extractor(resized_face)\n",
    "                    features.append(feature)\n",
    "                    labels.append(folder_name)\n",
    "                else:\n",
    "                    print(f\"Failed to detect face in image: {image_path}\")\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "def apply_pca(features, variance_threshold):\n",
    "    pca = PCA(n_components = variance_threshold, svd_solver='full')\n",
    "    pca.fit(features)\n",
    "    features_reduced = pca.transform(features)\n",
    "    return features_reduced, pca\n",
    "\n",
    "# Funktion zur Berechnung des Durchschnitts der Merkmale für jede Klasse\n",
    "def calculate_average_features_by_class(features, labels):\n",
    "    features_by_class = {}\n",
    "    class_counts = {}\n",
    "\n",
    "    # Iteration über Merkmale und Labels\n",
    "    for feature, label in zip(features, labels):\n",
    "        if label not in features_by_class:\n",
    "            features_by_class[label] = [feature]\n",
    "            class_counts[label] = 1\n",
    "        else:\n",
    "            features_by_class[label].append(feature)\n",
    "            class_counts[label] += 1\n",
    "\n",
    "    # Berechnung des Durchschnitts der Merkmale für jede Klasse\n",
    "    average_features = []\n",
    "    class_labels = []\n",
    "\n",
    "    for label, features_list in features_by_class.items():\n",
    "        average_feature = np.mean(features_list, axis=0)\n",
    "        average_features.append(average_feature)\n",
    "        class_labels.append(label)\n",
    "\n",
    "    return np.array(average_features), np.array(class_labels), class_counts\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face detection auf zu trainierenden Bildern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pfad zum Ordner mit den Unterordnern für jede Person\n",
    "base_path = \"Bilder\"\n",
    "\n",
    "# Zielordner für die geschnittenen Gesichter\n",
    "output_folder = 'Bilder_detected_faces'\n",
    "\n",
    "# Erstellen des Zielordners, falls er noch nicht existiert\n",
    "output_path = output_folder\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Durchlaufen der Ordner im Basispfad\n",
    "for person_folder in os.listdir(base_path):\n",
    "    person_folder_path = os.path.join(base_path, person_folder)\n",
    "    # Überprüfen, ob es sich um einen Ordner handelt\n",
    "    if os.path.isdir(person_folder_path):\n",
    "        # Durchlaufen der Bilder im Unterordner\n",
    "        for filename in os.listdir(person_folder_path):\n",
    "            image_path = os.path.join(person_folder_path, filename)\n",
    "            # Gesichtserkennung durchführen\n",
    "            face = detect_face(image_path)\n",
    "            if face is not None:\n",
    "                # Pfad für das ausgeschnittene Gesicht\n",
    "                new_folder_path = os.path.join(output_path, person_folder)\n",
    "                os.makedirs(new_folder_path, exist_ok=True)\n",
    "                new_image_path = os.path.join(new_folder_path, f\"{filename.split('.')[0]}_face.jpg\")\n",
    "                # Speichern des ausgeschnittenen Gesichts als neues Bild\n",
    "                cv2.imwrite(new_image_path, face)\n",
    "                print(f\"Gesicht in {filename} wurde erfolgreich ausgeschnitten und als {new_image_path} gespeichert.\")\n",
    "            else:\n",
    "                print(f\"Fehler beim Ausschneiden des Gesichts in {filename}.\")\n",
    "\n",
    "print(\"Gesichtserkennung und Ausschneiden abgeschlossen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstelle Augmented Bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the dataset folder\n",
    "data_folder = \"Bilder_detected_faces\"\n",
    "\n",
    "# Liste zum Speichern der Bilder und ihrer Labels\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "# Iterate over the folders in the dataset folder\n",
    "for folder_name in os.listdir(data_folder):\n",
    "    folder_path = os.path.join(data_folder, folder_name)\n",
    "    # Check if the item is a folder\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Iterate over the files in the folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            # Assuming the files are image files, you can adjust the file type according to your dataset\n",
    "            # Read the image using OpenCV\n",
    "            if file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(folder_path, file_name)\n",
    "                image = cv2.imread(image_path)\n",
    "                # Check if the image is loaded successfully\n",
    "                if image is not None:\n",
    "                    # Convert the image from BGR to RGB\n",
    "                    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    # Resize the image to a desired size\n",
    "                    resized_image = cv2.resize(rgb_image, (255, 255))\n",
    "                    # Perform image augmentation using Keras ImageDataGenerator\n",
    "                    datagen = ImageDataGenerator(\n",
    "                        rotation_range=20,\n",
    "                        width_shift_range=0.2,\n",
    "                        height_shift_range=0.2,\n",
    "                        shear_range=0.2,\n",
    "                        zoom_range=0.2,\n",
    "                        horizontal_flip=True,\n",
    "                        fill_mode='constant'\n",
    "                    )\n",
    "                    # Reshape the image to add batch dimension\n",
    "                    reshaped_image = resized_image.reshape((1,) + resized_image.shape)\n",
    "                    # Generate augmented images and append to the list\n",
    "                    i = 0\n",
    "                    for batch in datagen.flow(reshaped_image, batch_size=1):\n",
    "                        augmented_image = batch[0].astype(np.uint8)\n",
    "                        augmented_images.append(augmented_image)\n",
    "                        augmented_labels.append(folder_name)  # Hinzufügen des Labels (Ordnername)\n",
    "                        i += 1\n",
    "                        if i >= 200:\n",
    "                            break  # Break the loop after generating 100 augmented images\n",
    "                else:\n",
    "                    print(f\"Failed to load image: {image_path}\")\n",
    "            else:\n",
    "                print(f\"Skipping non-image file: {file_name}\")\n",
    "\n",
    "# Ausgabe der Anzahl der geladenen Bilder\n",
    "print(f\"Total images: {len(augmented_images)}\")\n",
    "print(f\"Total labels: {len(augmented_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hog Training Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store HOG features and labels\n",
    "hog_features = []\n",
    "hog_labels = []\n",
    "\n",
    "# Iterate over the images and labels in the lists\n",
    "for image, label in zip(augmented_images, augmented_labels):\n",
    "    hog_feature = extract_hog_features(image)\n",
    "    # Add the HOG feature to the list of features\n",
    "    hog_features.append(np.array(hog_feature))\n",
    "    # Add the label to the list of labels\n",
    "    hog_labels.append(label)\n",
    "    # Print HOG features and label\n",
    "    print(f\"HOG features: {hog_feature}, Label: {label}\")\n",
    "\n",
    "hog_features_array = np.array(hog_features)\n",
    "hog_features_reshaped = hog_features_array.reshape(len(hog_features), -1)\n",
    "hog_features, hog_pca_transformer = apply_pca(hog_features_reshaped, 0.95)\n",
    "print(f\"Total HOG features: {len(hog_features)}\")\n",
    "print(f\"Total labels: {len(hog_labels)}\")\n",
    "\n",
    "# Dateipfad, um den PCA-Transformer zu speichern\n",
    "hog_pca_transformer_path = \"hog_pca_transformer.pkl\"\n",
    "# Speichern des trainierten PCA-Transformers\n",
    "joblib.dump(hog_pca_transformer, hog_pca_transformer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBP Training Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store LBP features\n",
    "lbp_features = []\n",
    "lbp_labels = []\n",
    "\n",
    "# Iterate over the images and labels in the lists\n",
    "for image, label in zip(augmented_images, augmented_labels):\n",
    "    # Extract LBP features\n",
    "    lbp_feature = extract_lbp_features(image)\n",
    "    # Flatten the LBP feature array and append to the list of features\n",
    "    lbp_features.append(lbp_feature)\n",
    "    # Add the label to the list of labels\n",
    "    lbp_labels.append(label)\n",
    "    # Print LBP features and label\n",
    "\n",
    "    print(f\"LBP features: {lbp_feature}, Label: {label}\")\n",
    "\n",
    "\n",
    "#lbp_features_array = np.array(lbp_features)\n",
    "#lbp_features_reshaped = lbp_features_array.reshape(len(lbp_features), -1)\n",
    "#anzahl_samples = lbp_features_reshaped.shape[0]\n",
    "#print(\"Anzahl der Samples:\", anzahl_samples)\n",
    "print(f\"Total LBP features: {len(lbp_features)}\")\n",
    "print(f\"Total labels: {len(lbp_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lbp Random Forest\n",
    "# Laden der Trainingsdaten für LBP\n",
    "X_train_lbp = lbp_features\n",
    "y_train_lbp = lbp_labels\n",
    "\n",
    "# Laden der Testdaten für LBP\n",
    "X_test_lbp, y_test_lbp = load_images_and_extract_features(\"Test\", lambda img: extract_lbp_features(img))\n",
    "\n",
    "# Initialisierung des Random-Forest-Klassifikators\n",
    "rf_classifier_lbp = RandomForestClassifier(n_estimators=700, max_depth=20, random_state=42, n_jobs=-1, verbose=0 , max_features='sqrt', criterion='gini')\n",
    " \n",
    "# Durchführung der Kreuzvalidierung mit 5 Faltungen\n",
    "cv_scores_lbp = cross_val_score(rf_classifier_lbp, X_train_lbp, y_train_lbp, cv=5)\n",
    "\n",
    "# Trainieren des Random-Forest-Modells auf dem gesamten Trainingsdatensatz\n",
    "rf_classifier_lbp.fit(X_train_lbp, y_train_lbp)\n",
    " \n",
    "# Evaluierung des Modells auf den Testdaten für LBP\n",
    "accuracy_lbp = rf_classifier_lbp.score(X_test_lbp, y_test_lbp)\n",
    "predicted_lbp = rf_classifier_lbp.predict(X_test_lbp)\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "print(\"Cross-Validation Scores lbp:\", cv_scores_lbp)\n",
    "print(\"Mean Accuracy (Cross-Validation) lbp:\", cv_scores_lbp.mean())\n",
    "print(\"Accuracy (Test Set) lbp:\", accuracy_lbp)\n",
    "print(\"Predicted (Test Set) lbp:\", predicted_lbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HOG Randon Forest\n",
    "X_train_hog = hog_features\n",
    "y_train_hog = hog_labels\n",
    "\n",
    "# Laden der Testdaten für HOG\n",
    "X_test_hog, y_test_hog = load_images_and_extract_features(\"Test\", lambda img: extract_hog_features(img))\n",
    "\n",
    "print(f\"Total HOG features: {len(X_train_hog)}\")\n",
    "# Initialisierung des Random-Forest-Klassifikators\n",
    "rf_classifier_hog = RandomForestClassifier(n_estimators=300, max_depth=10, random_state=42, n_jobs=-1, verbose=0, max_features='sqrt', criterion= 'entropy')\n",
    "\n",
    "# Durchführung der Kreuzvalidierung mit 5 Faltungen\n",
    "cv_scores = cross_val_score(rf_classifier_hog, X_train_hog, y_train_hog, cv=5)\n",
    "\n",
    "# Trainieren des Random-Forest-Modells auf dem gesamten Trainingsdatensatz\n",
    "rf_classifier_hog.fit(X_train_hog, y_train_hog)\n",
    "\n",
    "# Classifiers speichern\n",
    "rf_classifier_hog_path = \"rf_classifier_hog.pkl\"\n",
    "joblib.dump(rf_classifier_hog, rf_classifier_hog_path)\n",
    "# Iteration über jedes Bild im Testdatensatz und Klassifizierung\n",
    "correct_predictions = 0\n",
    "for i, image in enumerate(X_test_hog):\n",
    "    # Anwenden des PCA-Transformers auf das Bild\n",
    "    image_pca = hog_pca_transformer.transform(image.reshape(1, -1))\n",
    "    # Durchführen der Vorhersage mit dem trainierten Modell\n",
    "    prediction = rf_classifier_hog.predict(image_pca)\n",
    "    # Ausgabe der Vorhersage für jedes Bild\n",
    "    print(f\"Prediction for image {i+1}: {prediction}\")\n",
    "    if prediction == y_test_hog[i]:\n",
    "        correct_predictions += 1\n",
    "    # Berechnung der Genauigkeit\n",
    "    accuracy = correct_predictions / len(y_test_hog)\n",
    "\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "print(\"Cross-Validation Scores hog:\", cv_scores)\n",
    "print(\"Mean Accuracy (Cross-Validation) hog:\", cv_scores.mean())\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilder predicten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordnerpfad mit den zu klassifizierenden Bildern\n",
    "predict_folder = \"predict\"\n",
    "\n",
    "# Iteriere über die Bilder im Ordner und führe die Vorhersage durch\n",
    "for filename in os.listdir(predict_folder):\n",
    "    image_path = os.path.join(predict_folder, filename)\n",
    "    # Gesichtserkennung durchführen\n",
    "    face = detect_face(image_path)\n",
    "    if face is not None:\n",
    "        # Plotte das Originalbild mit dem markierten Gesicht\n",
    "        plt.imshow(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title('Detected Face')\n",
    "        plt.show()\n",
    "\n",
    "    # Vorhersage mit HOG durchführen\n",
    "        prediction, confidence = predict_image_HOG(face, rf_classifier_hog, hog_pca_transformer)\n",
    "        if prediction is not None:\n",
    "            print(f\"Prediction HOG for {filename}: {prediction}, Confidence: {confidence}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to detect face in {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordnerpfad mit den zu klassifizierenden Bildern\n",
    "predict_folder = \"predict\"\n",
    "\n",
    "# Iteriere über die Bilder im Ordner und führe die Vorhersage durch\n",
    "for filename in os.listdir(predict_folder):\n",
    "    image_path = os.path.join(predict_folder, filename)\n",
    "    # Gesichtserkennung durchführen\n",
    "    face = detect_face(image_path)\n",
    "    if face is not None:\n",
    "        # Plotte das Originalbild mit dem markierten Gesicht\n",
    "        plt.imshow(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title('Detected Face')\n",
    "        plt.show()\n",
    "        \n",
    "        # Vorhersage mit LBP durchführen\n",
    "        if rf_classifier_lbp is not None:\n",
    "            prediction, confidence = predict_image_LBP(face, rf_classifier_lbp)\n",
    "            if prediction is not None:\n",
    "                print(f\"Prediction LBP for {filename}: {prediction}, Confidence: {confidence}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to detect face in {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Visualisieren HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung des Durchschnitts der HOG-Merkmale für jede Klasse\n",
    "average_hog_features_by_class, hog_class_labels, hog_class_counts = calculate_average_features_by_class(hog_features, hog_labels)\n",
    "\n",
    "# Visualisierung der durchschnittlichen HOG-Merkmale für jede Klasse\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, label in enumerate(hog_class_labels):\n",
    "    plt.plot(average_hog_features_by_class[i], label=f'Class {label} (n={hog_class_counts[label]})')\n",
    "\n",
    "plt.xlabel('HOG Feature Index')\n",
    "plt.ylabel('Average Value')\n",
    "plt.title('Average HOG Features by Class')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Visualisieren LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung des Durchschnitts der LBP-Merkmale für jede Klasse\n",
    "average_lbp_features_by_class, lbp_class_labels, lbp_class_counts = calculate_average_features_by_class(lbp_features, lbp_labels)\n",
    "\n",
    "# Visualisierung der durchschnittlichen LBP-Merkmale für jede Klasse\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, label in enumerate(lbp_class_labels):\n",
    "    plt.plot(average_lbp_features_by_class[i], label=f'Class {label} (n={lbp_class_counts[label]})')\n",
    "\n",
    "plt.xlabel('LBP Feature Index')\n",
    "plt.ylabel('Average Value')\n",
    "plt.title('Average LBP Features by Class')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facerecognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
