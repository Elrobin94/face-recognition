{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstelle Augmented Bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the dataset folder\n",
    "data_folder = \"Bilder\"\n",
    "\n",
    "# Define the new subfolder name for augmented images\n",
    "new_subfolder = \"Augmented\"\n",
    "\n",
    "# Define the path to the dataset folder\n",
    "data_folder = \"Bilder\"\n",
    "\n",
    "# Define the new subfolder name for augmented images\n",
    "new_subfolder = \"Augmented\"\n",
    "\n",
    "# Iterate over the folders in the dataset folder\n",
    "for folder_name in os.listdir(data_folder):\n",
    "    folder_path = os.path.join(data_folder, folder_name)\n",
    "    # Check if the item is a folder\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Create a new subfolder for augmented images\n",
    "        new_folder_path = os.path.join(folder_path, new_subfolder)\n",
    "        os.makedirs(new_folder_path, exist_ok=True)\n",
    "        # Iterate over the files in the folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            # Assuming the files are image files, you can adjust the file type according to your dataset\n",
    "            # Read the image using OpenCV\n",
    "            if file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(folder_path, file_name)\n",
    "                image = cv2.imread(image_path)\n",
    "                # Check if the image is loaded successfully\n",
    "                if image is not None:\n",
    "                    # Perform image augmentation\n",
    "                    # Resize the image to a desired size\n",
    "                    resized_image = cv2.resize(image, (300, 300))\n",
    "                    datagen = ImageDataGenerator(\n",
    "                        rotation_range=40,\n",
    "                        width_shift_range=0.2,\n",
    "                        height_shift_range=0.2,\n",
    "                        shear_range=0.2,\n",
    "                        zoom_range=0.2,\n",
    "                        horizontal_flip=True,\n",
    "                        fill_mode='nearest'\n",
    "                    )\n",
    "                    # Reshape the image to add batch dimension\n",
    "                    reshaped_image = resized_image.reshape((1,) + resized_image.shape)\n",
    "                    # Generate and save augmented images\n",
    "                    i = 0\n",
    "                    for batch in datagen.flow(reshaped_image, batch_size=1, save_to_dir=new_folder_path, save_prefix='aug', save_format='png'):\n",
    "                        i += 1\n",
    "                        if i >= 10:\n",
    "                            break  # Break the loop after generating 100 augmented images\n",
    "                else:\n",
    "                    print(f\"Failed to load image: {image_path}\")\n",
    "            else:\n",
    "                print(f\"Skipping non-image file: {file_name}\")\n",
    "           \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vektorize Bilder und erstelle Labels dazu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Iterate over the folders in the dataset folder\n",
    "for folder_name in os.listdir(data_folder):\n",
    "    folder_path = os.path.join(data_folder, folder_name)\n",
    "    # Check if the item is a folder\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Get the label from the folder name\n",
    "        label = folder_name\n",
    "        # Get the path to the augmented folder\n",
    "        augmented_folder_path = os.path.join(folder_path, new_subfolder)\n",
    "        # Check if the augmented folder exists\n",
    "        if os.path.exists(augmented_folder_path):\n",
    "            # Iterate over the files in the augmented folder\n",
    "            for file_name in os.listdir(augmented_folder_path):\n",
    "                # Read the image using OpenCV\n",
    "                image_path = os.path.join(augmented_folder_path, file_name)\n",
    "                image = cv2.imread(image_path)\n",
    "                # Check if the image is loaded successfully\n",
    "                if image is not None:\n",
    "                    # Add the image to the list of images\n",
    "                    images.append(image)\n",
    "                    # Add the label to the list of labels\n",
    "                    labels.append(label)\n",
    "                else:\n",
    "                    print(f\"Failed to load image: {image_path}\")\n",
    "\n",
    "print(f\"Total images: {len(images)}\")\n",
    "print(f\"Total labels: {len(labels)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hog Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "import cv2\n",
    "\n",
    "# Initialize empty lists to store HOG features and labels\n",
    "hog_features = []\n",
    "hog_labels = []\n",
    "\n",
    "# Iterate over the folders in the dataset folder\n",
    "for folder_name in os.listdir(data_folder):\n",
    "    folder_path = os.path.join(data_folder, folder_name)\n",
    "    # Check if the item is a folder\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Get the path to the augmented folder\n",
    "        augmented_folder_path = os.path.join(folder_path, new_subfolder)\n",
    "        # Check if the augmented folder exists\n",
    "        if os.path.exists(augmented_folder_path):\n",
    "            # Iterate over the files in the augmented folder\n",
    "            for file_name in os.listdir(augmented_folder_path):\n",
    "                # Read the image using OpenCV\n",
    "                image_path = os.path.join(augmented_folder_path, file_name)\n",
    "                image = cv2.imread(image_path)\n",
    "                # Check if the image is loaded successfully\n",
    "                if image is not None:\n",
    "                    # Convert the image to grayscale\n",
    "                    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                    # Perform HOG feature extraction\n",
    "                    hog_feature = hog(gray_image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False)\n",
    "                    # Add the HOG feature to the list of features\n",
    "                    hog_features.append(hog_feature)\n",
    "                    # Add the label to the list of labels\n",
    "                    hog_labels.append(folder_name)\n",
    "                    # Print image filename, HOG features, and label\n",
    "                    print(f\"Image: {file_name}, HOG features: {hog_feature}, Label: {folder_name}\")\n",
    "                else:\n",
    "                    print(f\"Failed to load image: {image_path}\")\n",
    "\n",
    "print(f\"Total HOG features: {len(hog_features)}\")\n",
    "print(f\"Total labels: {len(labels)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lbp_features(image, num_points, radius):\n",
    "    lbp_features = []\n",
    "    for channel in range(image.shape[2]):  # Iteriere über die Farbkanäle (RGB)\n",
    "        lbp = local_binary_pattern(image[:, :, channel], num_points, radius, method='uniform')\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, num_points + 3), range=(0, num_points + 2))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + 1e-7)\n",
    "        lbp_features.extend(hist)\n",
    "    return lbp_features\n",
    "\n",
    "def predict_image_LBP(image_path, classifier, num_points, radius):\n",
    "    # Lade das Bild\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is not None:\n",
    "        # Verkleinere das Bild\n",
    "        resized_image = cv2.resize(image, (300, 300))\n",
    "        # Extrahiere die LBP-Merkmale\n",
    "        lbp_features = extract_lbp_features(resized_image, num_points, radius)\n",
    "        # Führe die Vorhersage mit dem Klassifikator durch\n",
    "        prediction = classifier.predict([lbp_features])[0]\n",
    "        # Bestimme die Vertrauenswahrscheinlichkeit für die Vorhersage\n",
    "        confidence = max(classifier.predict_proba([lbp_features])[0])\n",
    "        return prediction, confidence\n",
    "    else:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBP Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize empty list to store LBP features\n",
    "lbp_features = []\n",
    "lbp_labels = []\n",
    " \n",
    "# Parameter für LBP festlegen\n",
    "num_points = 24\n",
    "radius = 2\n",
    "\n",
    "for folder_name in os.listdir(data_folder):\n",
    "    folder_path = os.path.join(data_folder, folder_name)\n",
    "    # Check if the item is a folder\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Get the path to the augmented folder\n",
    "        augmented_folder_path = os.path.join(folder_path, new_subfolder)\n",
    "        # Check if the augmented folder exists\n",
    "        if os.path.exists(augmented_folder_path):\n",
    "            # Iterate over the files in the augmented folder\n",
    "            for file_name in os.listdir(augmented_folder_path):\n",
    "                # Read the image using OpenCV\n",
    "                image_path = os.path.join(augmented_folder_path, file_name)\n",
    "                image = cv2.imread(image_path)\n",
    "                # Check if the image is loaded successfully\n",
    "                if image is not None:\n",
    "                    lbp_feature = extract_lbp_features(image, num_points, radius)\n",
    "                    lbp_features.append(lbp_feature)\n",
    "                    # Add the label to the list of labels\n",
    "                    lbp_labels.append(folder_name)\n",
    "                    print(f\"Image: {file_name}, LBP features: {lbp_feature}, Label: {folder_name}\")\n",
    "                else:\n",
    "                    print(f\"Failed to load image: {image_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Aufteilung der Daten in Trainings- und Testsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(lbp_features, labels, test_size=0.2, random_state=42)\n",
    " \n",
    "# Initialisierung des Random-Forest-Klassifikators\n",
    "rf_classifier = RandomForestClassifier(n_estimators=10, random_state=42, n_jobs=-1, verbose=1 , max_depth=10)\n",
    " \n",
    "# Durchführung der Kreuzvalidierung mit 5 Faltungen\n",
    "cv_scores = cross_val_score(rf_classifier, X_train, y_train, cv=5)\n",
    "\n",
    "# Trainieren des Random-Forest-Modells auf dem gesamten Trainingsdatensatz\n",
    "rf_classifier.fit(X_train, y_train)\n",
    " \n",
    "# Evaluierung des Modells auf dem Testdatensatz (optional)\n",
    "accuracy = rf_classifier.score(X_test, y_test)\n",
    "predicted = rf_classifier.predict(X_test)\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy (Cross-Validation):\", cv_scores.mean())\n",
    "print(\"Accuracy (Test Set):\", accuracy)\n",
    "print(\"Predicted (Test Set):\", predicted)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilder predicten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordnerpfad mit den zu klassifizierenden Bildern\n",
    "predict_folder = \"predict\"\n",
    "\n",
    "# Iteriere über die Bilder im Ordner und führe die Vorhersage durch\n",
    "for filename in os.listdir(predict_folder):\n",
    "    image_path = os.path.join(predict_folder, filename)\n",
    "    prediction, confidence = predict_image_LBP(image_path, rf_classifier, num_points, radius)\n",
    "    if prediction is not None:\n",
    "        print(f\"Prediction for {filename}: {prediction}, Confidence: {confidence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
