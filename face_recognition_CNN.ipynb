{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten,BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import glob\n",
    "import joblib\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(image_path):\n",
    "    # Laden des Gesichtserkennungs-Klassifikators (Haar-Cascade)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    # Laden des Bildes\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is not None:\n",
    "        # Konvertieren des Bildes in Graustufen\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # Gesichter im Bild erkennen\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(200, 200))\n",
    "        if len(faces) > 0:\n",
    "            # Nehme das erste erkannte Gesicht\n",
    "            (x, y, w, h) = faces[0]\n",
    "            # Schneide das Gesicht aus\n",
    "            face = image[y:y+h, x:x+w]\n",
    "             # Zeichne ein Rechteck um das erkannte Gesicht\n",
    "            ##cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            return face\n",
    "        else:\n",
    "            print(f\"No face detected in {image_path}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize data into train and test dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved face_dataset\\train\\nino\\20240403_185115.jpg\n",
      "Saved face_dataset\\train\\nino\\20240403_185035.jpg\n",
      "Saved face_dataset\\train\\nino\\20240403_185511.jpg\n",
      "Saved face_dataset\\train\\nino\\20240403_185256.jpg\n",
      "Saved face_dataset\\train\\nino\\20240403_185237.jpg\n",
      "Saved face_dataset\\train\\nino\\20240403_185047.jpg\n",
      "Saved face_dataset\\train\\nino\\20240403_185058.jpg\n",
      "Saved face_dataset\\train\\nino\\20240403_1851150.jpg\n",
      "Saved face_dataset\\train\\nino\\20240403_185526.jpg\n",
      "Saved face_dataset\\train\\nino\\20240403_185045.jpg\n",
      "Saved face_dataset\\train\\nino\\image (4).jpg\n",
      "Saved face_dataset\\train\\nino\\image (1).jpg\n",
      "Saved face_dataset\\train\\nino\\20240403_185543.jpg\n",
      "Saved face_dataset\\train\\nino\\20240403_185329.jpg\n",
      "Saved face_dataset\\valid\\nino\\20240403_185308.jpg\n",
      "Saved face_dataset\\valid\\nino\\20240403_185058.jpg\n",
      "Saved face_dataset\\valid\\nino\\image.jpg\n",
      "Saved face_dataset\\valid\\nino\\20240403_185526.jpg\n",
      "Saved face_dataset\\valid\\nino\\20240403_185543.jpg\n",
      "Saved face_dataset\\valid\\nino\\20240403_185329.jpg\n",
      "Saved face_dataset\\test\\nino\\20240403_185047.jpg\n",
      "Saved face_dataset\\test\\nino\\20240403_185115.jpg\n",
      "Saved face_dataset\\test\\nino\\20240403_185543.jpg\n",
      "Saved face_dataset\\test\\nino\\20240403_185237.jpg\n",
      "Saved face_dataset\\train\\robin\\20240403_192344.jpg\n",
      "Saved face_dataset\\train\\robin\\20240326_111717.jpg\n",
      "Saved face_dataset\\train\\robin\\robin7.jpg\n",
      "Saved face_dataset\\train\\robin\\20240326_111707.jpg\n",
      "Saved face_dataset\\train\\robin\\20240403_192400.jpg\n",
      "Saved face_dataset\\train\\robin\\20240403_192350.jpg\n",
      "Saved face_dataset\\train\\robin\\20240403_192434.jpg\n",
      "Saved face_dataset\\train\\robin\\20240403_192324.jpg\n",
      "Saved face_dataset\\train\\robin\\20240403_192443.jpg\n",
      "Saved face_dataset\\train\\robin\\20240403_192402.jpg\n",
      "Saved face_dataset\\train\\robin\\robin22.jpg\n",
      "Saved face_dataset\\train\\robin\\robin123.jpg\n",
      "Saved face_dataset\\train\\robin\\20240326_154713.jpg\n",
      "Saved face_dataset\\train\\robin\\20240403_192441.jpg\n",
      "Saved face_dataset\\valid\\robin\\robin8_face.jpg\n",
      "Saved face_dataset\\valid\\robin\\20240326_154713.jpg\n",
      "Saved face_dataset\\valid\\robin\\robin121_face.jpg\n",
      "Saved face_dataset\\valid\\robin\\20240403_192402.jpg\n",
      "Saved face_dataset\\valid\\robin\\robin123.jpg\n",
      "Saved face_dataset\\valid\\robin\\20240403_192430.jpg\n",
      "Saved face_dataset\\test\\robin\\20240403_192443.jpg\n",
      "Saved face_dataset\\test\\robin\\robin7.jpg\n",
      "Saved face_dataset\\test\\robin\\20240326_154713.jpg\n",
      "Saved face_dataset\\test\\robin\\robin22.jpg\n"
     ]
    }
   ],
   "source": [
    "# Ordnerstruktur erstellen und Bilder kopieren\n",
    "def create_dataset_with_face_detection(src_dir, dest_dir):\n",
    "    # Erstellen der Ordnerstruktur\n",
    "    for class_name in ['nino', 'robin']:\n",
    "        for dataset_type in ['train', 'valid', 'test']:\n",
    "            os.makedirs(os.path.join(dest_dir, dataset_type, class_name), exist_ok=True)\n",
    "\n",
    "    # Kopieren der Bilder mit Gesichtserkennung\n",
    "    for class_name in ['nino', 'robin']:\n",
    "        image_files = glob.glob(os.path.join(src_dir, class_name, '*'))\n",
    "        for dataset_type in ['train', 'valid', 'test']:\n",
    "            if dataset_type == 'train':\n",
    "                num_images_to_copy = 14\n",
    "            elif dataset_type == 'valid':\n",
    "                num_images_to_copy = 6\n",
    "            else:\n",
    "                num_images_to_copy = 4\n",
    "                \n",
    "            selected_images = random.sample(image_files, num_images_to_copy)\n",
    "            for image_path in selected_images:\n",
    "                face = detect_face(image_path)\n",
    "                if face is not None:\n",
    "                    dest_path = os.path.join(dest_dir, dataset_type, class_name, os.path.basename(image_path))\n",
    "                    cv2.imwrite(dest_path, face)\n",
    "                    print(f\"Saved {dest_path}\")\n",
    "\n",
    "# Pfad zum Quellverzeichnis der Bilder\n",
    "src_dir = 'archive'\n",
    "\n",
    "# Pfad zum Zielverzeichnis der Trainings-, Validierungs- und Testbilder\n",
    "dest_dir = 'face_dataset'\n",
    "\n",
    "# Erstellen der Datensätze mit Gesichtserkennung\n",
    "create_dataset_with_face_detection(src_dir, dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('face_dataset')\n",
    "if os.path.isdir('train/nino') is False:\n",
    "    os.makedirs('train/nino')\n",
    "    os.makedirs('train/robin')\n",
    "    os.makedirs('valid/nino')\n",
    "    os.makedirs('valid/robin')\n",
    "    os.makedirs('test/nino')\n",
    "    os.makedirs('test/robin')\n",
    "    \n",
    "    for c in random.sample(glob.glob('robin/*'), 16):\n",
    "        shutil.copy(c, 'train/robin/' + os.path.basename(c))\n",
    "    for c in random.sample(glob.glob('nino/*'), 16):\n",
    "        shutil.copy(c, 'train/nino/' + os.path.basename(c))\n",
    "    for c in random.sample(glob.glob('robin/*'), 4):\n",
    "        shutil.copy(c, 'valid/robin/'+ os.path.basename(c))\n",
    "    for c in random.sample(glob.glob('nino/*'), 4):\n",
    "        shutil.copy(c, 'valid/nino/'+ os.path.basename(c))\n",
    "    for c in random.sample(glob.glob('robin/*'), 4):\n",
    "        shutil.copy(c, 'test/robin/'+ os.path.basename(c))\n",
    "    for c in random.sample(glob.glob('nino/*'), 4):\n",
    "        shutil.copy(c, 'test/nino/'+ os.path.basename(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'face_dataset/train'\n",
    "valid_path = 'face_dataset/valid'\n",
    "test_path = 'face_dataset/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Das System kann den angegebenen Pfad nicht finden: 'face_dataset/train/nino'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 35\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Erstellen eines ImageDataGenerator für die Augmentierung\u001b[39;00m\n\u001b[0;32m     25\u001b[0m datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m     26\u001b[0m     rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     27\u001b[0m     width_shift_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     fill_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     33\u001b[0m     )\n\u001b[1;32m---> 35\u001b[0m \u001b[43maugment\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_dir_nino\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmented_dir_nino\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m augment(original_dir_robin, augmented_dir_robin)\n",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m, in \u001b[0;36maugment\u001b[1;34m(original_dir, augmented_dir)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maugment\u001b[39m(original_dir, augmented_dir):\n\u001b[1;32m----> 3\u001b[0m     image_files \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(original_dir, f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(original_dir, f))]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Augmentierung und Speichern der Bilder\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image_file \u001b[38;5;129;01min\u001b[39;00m image_files:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Das System kann den angegebenen Pfad nicht finden: 'face_dataset/train/nino'"
     ]
    }
   ],
   "source": [
    "# Laden der Bilder aus dem Originalverzeichnis\n",
    "def augment(original_dir, augmented_dir):\n",
    "    image_files = [os.path.join(original_dir, f) for f in os.listdir(original_dir) if os.path.isfile(os.path.join(original_dir, f))]\n",
    "    # Augmentierung und Speichern der Bilder\n",
    "    for image_file in image_files:\n",
    "        img = cv2.imread(image_file) # Hier die Funktion für das Laden und eventuelle Vorverarbeitung des Bildes einsetzen\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = img.reshape((1,) + img.shape)  # Reshape zu (1, height, width, channels) für den Generator\n",
    "        i = 0\n",
    "        for batch in datagen.flow(img, batch_size=1, save_to_dir=augmented_dir, save_prefix='augmented', save_format='jpg'):\n",
    "            i += 1\n",
    "            if i >= 10:  # Anzahl der zu generierenden augmentierten Bilder pro Originalbild\n",
    "                break  # Abbruch, wenn die gewünschte Anzahl erreicht ist\n",
    "\n",
    "\n",
    "# Verzeichnis mit den Originalbildern\n",
    "original_dir_nino = 'face_dataset/train/nino'\n",
    "original_dir_robin = 'face_dataset/train/robin'\n",
    "# Verzeichnis, in das die augmentierten Bilder gespeichert werden sollen\n",
    "augmented_dir_nino = 'face_dataset/train/nino'\n",
    "augmented_dir_robin = 'face_dataset/train/robin'\n",
    "\n",
    "# Erstellen eines ImageDataGenerator für die Augmentierung\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='constant'\n",
    "    )\n",
    "\n",
    "augment(original_dir_nino, augmented_dir_nino)\n",
    "augment(original_dir_robin, augmented_dir_robin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['robin', 'nino'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(224,224), classes=['robin', 'nino'], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(224,224), classes=['robin', 'nino'], batch_size=10, shuffle=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Plotten von Bildern aus einem Bildgenerator\n",
    "def plot_images(generator, num_images=5):\n",
    "    # Lade eine Batch von Bildern\n",
    "    images, labels = next(generator)\n",
    "    \n",
    "    # Plotte die ersten num_images Bilder\n",
    "    for i in range(num_images):\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"Class: {labels[i]}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Plotte Bilder aus dem Trainingsbatch\n",
    "print(\"Trainingsbilder:\")\n",
    "plot_images(train_batches)\n",
    "\n",
    "# Plotte Bilder aus dem Validierungsbatch\n",
    "print(\"Validierungsbilder:\")\n",
    "plot_images(valid_batches)\n",
    "\n",
    "# Plotte Bilder aus dem Testbatch\n",
    "print(\"Testbilder:\")\n",
    "plot_images(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImages(imgs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(5, 5), activation='relu', padding = 'same', input_shape=(224,224,3)),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    Conv2D(filters=64, kernel_size=(5, 5), activation='relu', padding = 'same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(units=2, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Convolutional Layer 2\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Convolutional Layer 3\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Flattening Layer\n",
    "    Flatten(),\n",
    "    \n",
    "    # Fully Connected Layer\n",
    "    Dense(units=512, activation='relu'),\n",
    "    \n",
    "    # Dropout Layer to reduce overfitting\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    # Output Layer\n",
    "    Dense(units=2, activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen eines Sequential-Modells\n",
    "model = Sequential()\n",
    "\n",
    "# Hinzufügen des VGG16-Modells\n",
    "model.add(VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)))\n",
    "\n",
    "# Einfrieren der Gewichte des VGG16-Modells, um sie während des Trainings nicht zu aktualisieren\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "# Hinzufügen der weiteren Schichten\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))  # Annahme von 2 Klassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n",
    "history = model.fit(x=train_batches, validation_data=valid_batches, epochs=10, verbose=2)\n",
    "\n",
    "test_imgs, test_labels = next(test_batches)\n",
    "\n",
    "test_batches.classes\n",
    "\n",
    "predictions = model.predict(x=test_batches, verbose=0)\n",
    "\n",
    "np.round(predictions)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Speichern des Modells\n",
    "model.save(\"E:/ZHAW/Semester4/Project/face-recognition/mein_keras_modell.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Festlegen der Anzahl der anzuzeigenden Bilder\n",
    "num_images_to_display = 8\n",
    "\n",
    "# Ausgabe der Vorhersagen und Zuversicht für die ersten num_images_to_display Bilder\n",
    "for i in range(num_images_to_display):\n",
    "    # Index des aktuellen Bilds\n",
    "    img_index = i\n",
    "    \n",
    "    # Vorhersagen für das aktuelle Bild\n",
    "    prediction = predictions[img_index]\n",
    "    \n",
    "    # Tatsächliche Klasse des aktuellen Bilds\n",
    "    actual_class = \"robin\" if test_labels[img_index][0] == 1 else \"nino\"\n",
    "    \n",
    "    # Vorhergesagte Klasse des aktuellen Bilds\n",
    "    predicted_class = \"robin\" if prediction[0] >= 0.5 else \"nino\"\n",
    "    \n",
    "    # Zuversicht (Sicherheit) der Vorhersage für die vorhergesagte Klasse\n",
    "    confidence = prediction[0] if predicted_class == \"robin\" else 1 - prediction[0]\n",
    "    \n",
    "    # Ausgabe der Vorhersage und Zuversicht\n",
    "    print(f\"Image {img_index + 1}: Actual Class = {actual_class}, Predicted Class = {predicted_class}, Confidence = {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                            normalize=False,\n",
    "                            title='Confusion matrix',\n",
    "                            cmap=plt.cm.Blues):\n",
    "        \"\"\"\n",
    "        This function prints and plots the confusion matrix.\n",
    "        Normalization can be applied by setting `normalize=True`.\n",
    "        \"\"\"\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "    \n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print(\"Normalized confusion matrix\")\n",
    "        else:\n",
    "            print('Confusion matrix, without normalization')\n",
    "    \n",
    "        print(cm)\n",
    "    \n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, cm[i, j],\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "cm_plot_labels = ['robin','nino']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
